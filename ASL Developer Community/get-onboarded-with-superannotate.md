# Get Onboarded with SuperAnnotate

NVIDIA, AWS, and SuperAnnotate are partnering to support the broader ASL and gesture research
community with scalable, accessible dataset creation tools. As part of the ongoing mission to help
teach and curate the world's largest dataset for American Sign Language (ASL), SIGNS helps users
learn sign language through their webcam with real-time feedback from an AI-driven 3D digital human.

The dataset includes high-fidelity video paired with MediaPipe-generated annotations such as hand
landmarks, body pose keypoints, and facial meshes - providing a strong foundation for ASL model
training and research.

SuperAnnotate offers a unified environment to explore, manage, and extend these annotations with
custom labeling workflows.

If you'd like to work with the dataset or configure your annotation pipeline, contact us here:
<https://www.superannotate.com/nvidia-asl-request>
